---
title: "mice example code"
author: "Marta Pineda-Moncusi"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
editor_options: 
  markdown: 
    wrap: 72
---

rm(list=ls())

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Tutorial for multiple imputation using mice package

*Introduction text: seven steps*

## 0. Load and evaluate the data

**The Hip Replacement (HIP) dataset**

We are going to use the hip.RData:

The hip dataset contains information on seven hundred and eight patients
receiving primary hip replacement surgery for osteoarthritis (variable
***id*** is the unique patient identifier). Prior to the operation,
patients completed a pre-operative Oxford Hip Score (OHS) and EQ5D
(Euroqol) questionnaire with a follow-up questionnaire being filled in
at 6-months post-surgery. The OHS consists of 12 questions asking
patients to describe their hip pain and function during the past 4
weeks. An overall score is created by summing the responses to each of
the 12 questions, ranging from 0 to 48, where 0 is the worst possible
score (severe symptoms) and 48 the best score (excellent joint
function). Variable ***ohs0*** is the preoperative score and ***ohs6***
post-operative. The absolute change in OHS between pre- and
post-operative assessments (variable ***ohsdiff***) is negative if
patient symptoms have improved and positive for worsening.

The pre-operative ***EQ5D*** contains information from 5 questions
asking about a patient's health state today, covering mobility,
self-care, usual activities, pain, and anxiety. The EQ5D has been
converted to a single summary score (variable EQ5D0), anchored at 0 for
death and 1 for full health, with some health states being worse than
dead (-0.594).

Six months after their operation patients were asked about their overall
satisfaction with the outcome of surgery measured on a visual analogue
scale from 0 to 100 (variable ***satisfaction***).

Pre-operative information was collected on age at the time of surgery,
***sex*** (0 = Male; 1 = Female), ***height*** (metres) and ***weight***
(kg) (from which body mass index (***bmi***) is calculated), ***side***
of surgery (Left; Right), ***ethnic*** group (0 = White; 1 = Non white),
whether or not they are ***retired*** (0 = Not retired; 1 = Retired).
The Index of Multiple Deprivation is a measure of social deprivation,
linked to the area a patient lives in (variable \*\**imdscore*).

\*\*The outcome of this study\*: improvement in the ohs (i.e., ohsdiff
\> 0)

```{r haven, dplyr}
#load data
library(haven)
data <- read_dta('C:/Users/msanchez/Documents/GitHub/Practical_Imputation/multiple-imputation_with_mice/hip.dta')
#transform/include labels to data
library(dplyr)
data = data %>% 
            mutate(sex = factor(sex, levels = c(0,1), labels = c("Male","Female")),
                 ethnic = factor(ethnic, levels = c(0,1), labels = c("White","Non white")),
                retired = factor(retired, levels = c(0,1), labels = c("Not retired","Retired")),
                improve = ifelse(ohsdiff<=0,0,1 ) #"NO","YES"
              )

#Observe data
dim(data)
summary(data)
#str(data)
```

Check the structure of the data:

-   How many cases (individuals) are in the data? 708
-   How many variables do we have? 17
-   Which are numeric? age, oh0, oh6, ohsdiff, EQ5D0, height, weight,
    satisfaction, bmi and imdscore
-   Which are factor? improve (but hasn't been formatted on propose),
    sex, retired, ethnic and side
-   Is there any variable with missing? EQ5D0, height, weight, bmi,
    satisfaction, ethnic and imdscore

## 1. Check that variables with missing data are associated with variables that are complete.

To do so, crate a dummy variable were missing values are 1 and complete
values are 0, and run a logistic regression.

```{r}

#list the variables you want to test
test_var_list = c("EQ5D0", "height", "weight", "bmi", "satisfaction", "ethnic", "imdscore")
complete_var  = c("age", "sex", "retired", "ohs0","ohs6", "side") #, "improve") #Q: Since the outcome ("ohsdiff") is a derivation from  "oh0" and "oh6", should we included here?

for (v in 1:length(test_var_list)){
 test_var = ifelse(is.na(data[[test_var_list[v]]]), 1,0 )
 test = glm(test_var ~ ., data=data[complete_var] )
  print(paste("Tested variable: ", test_var_list[v], sep="")) 
  print(summary(test))   #Check p_value
}

```

## 2. Check that your numeric variables are linear with your outcome.

```{r}
#list the variables you want to test
test_var_list = c("age", "ohs0", "ohs6", "ohsdiff", "EQ5D0", "height", "weight", "satisfaction", "bmi", "imdscore" )
outcome = "improve"

for (v in 1:length(test_var_list)){
  df = cbind(data[test_var_list[v]],outcome = data[[outcome]])
  #df= as.data.frame(df) #remove tibble
  test = lm(outcome ~ ., data = df)
  par(mfrow = c(2, 2))
  plot(test,main=paste(test_var_list[v],"\n",sep=""))
}
```

How to interpret the plots: The diagnostic plots show residuals in four
different ways \> **Residuals vs Fitted: Used to check the linear
relationship assumptions.** A horizontal line, without distinct patterns
is an indication for a linear relationship, what is good. \> Normal Q-Q:
Used to examine whether the residuals are normally distributed. It's
good if residuals points follow the straight dashed line. \>
Scale-Location (or Spread-Location): Used to check the homogeneity of
variance of the residuals (homoscedasticity). Horizontal line with
equally spread points is a good indication of homoscedasticity. \>
Residuals vs Leverage: Used to identify influential cases, that is
extreme values that might influence the regression results when included
or excluded from the analysis.

-   Which variables does follow a normal distribution?
-   Which variables does not follow a normal distribution?
-   What should we do? Transform the variables. Simplest e.g.
    Categorization

## 3. Choosing imputation methods.

There are nine methods available for imputing a variable: **regress,
pmm, truncreg, intreg, logit, ologit, mlogit, poisson and nbreg**. The
order of the imputed variables is key here.

\|-----\|-----\|-----\|-----\| \| Method \| Description \| Scale type \|
Default \| \|-----\|-----\|-----\|-----\| \| pmm \| Predictive mean
matching \| numeric \| Y \| \| norm \| Bayesian linear regression \|
numeric \| \| \| norm.nob \| Linear regression, non-Bayesian \| numeric
\| \| \| mean \| Unconditional mean imputation \| numeric \| \| \|
2L.norm \| Two-level linear model \| numeric \| \| \| logreg \| Logistic
regression \| factor, 2 levels \| Y \| \| polyreg \| Multinomial logit
model \| factor, \>2 levels \| Y \| \| polr \| Ordered logit model \|
ordered, \>2 levels \| Y \| \| lda \| Linear discriminant analysis \|
factor \| \| \| sample \| Random sample from the observed data \| any \|
\| \|-----\|-----\|-----\|-----\|

```{r}
#Variables to impute: EQ5D0, height, weight, bmi, satisfaction, ethnic, imdscore

names(data) #see order: "EQ5D0", "height", "weight","satisfaction", "bmi", "ethnic", "imdscore"
pred_list = c("EQ5D0", "height", "weight","satisfaction", "bmi", "ethnic", "imdscore")
methods = c("EQ5D0", "height", "weight","satisfaction", "bmi", "ethnic", "imdscore")

```

-   

    ------------------------------------------------------------------------

## 4. Missing value patterns

## 5. Interactions with sex

## 6. Imputations with mice

1.  First your create your m imputed datasets. (mice() - function)

2.  Then you do your analysis on each of these datasets. (with() -
    function)

3.  In the end you combine these results together. (pool() - function)

    ![](images/Steps_MI-01.png)

## 7. Pooling results

The pool() function combines the estimates from m repeated complete data
analyses. The typical sequence of steps to do a multiple imputation
analysis is:

Impute the missing data by the mice function, resulting in a multiple
imputed data set (class mids);

Fit the model of interest (scientific model) on each imputed data set by
the with() function, resulting an object of class mira;

Pool the estimates from each model into a single set of estimates and
standard errors, resulting is an object of class mipo;

Optionally, compare pooled estimates from different scientific models by
the pool.compare() function.

```{r }
library(mice)
# create the impute datasets
imp <- mice(data, maxit=10, m = 5) 
fit <- with(data=imp,exp=lm(bmi~age+sex+ethnic+imdscore))
summary(pool(fit))

```

## 8. checking after imputation
